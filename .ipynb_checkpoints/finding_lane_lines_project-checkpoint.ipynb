{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and plot the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load an image.\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "# show the orignal image.\n",
    "print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters.\n",
    "KERNEL_SIZE = 3\n",
    "LOW_THRESHOLD = 75   # threshold for canny edge detector\n",
    "HIGH_THRESHOLD = 150 # threshold for canny edge detector\n",
    "\n",
    "BOTTOM_SHIFT = 75    # use for creating area of interest region\n",
    "TOP_SHIFT = 40       # use for creating area of interest region\n",
    "\n",
    "RHO = 2              # distance resolution in pixels of the Hough grid\n",
    "THETA = np.pi/180    # angular resolution in radians of the Hough grid\n",
    "MIN_VOTES = 100      # minimum number of votes (intersections in Hough grid cell)\n",
    "MIN_LINE_LEN = 25    # minimum number of pixels making up a line\n",
    "MAX_LINE_GAP = 25    # maximum gap in pixels between connectable line segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"\n",
    "    Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"\n",
    "    Applies the Canny transform\n",
    "    \"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian Noise kernel\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def get_selected_region(image):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    top_left = (image_width / 2 - TOP_SHIFT, image_height / 2 + TOP_SHIFT)\n",
    "    top_right = (image_width /2 + TOP_SHIFT, image_height / 2 + TOP_SHIFT)\n",
    "    bottom_left = (BOTTOM_SHIFT, image_height)\n",
    "    bottom_right = (image_width - BOTTOM_SHIFT, image_height)\n",
    "    return top_left, top_right, bottom_left, bottom_right\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    # define a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # define a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # fill pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # return the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "        \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, \n",
    "                            np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=1, β=0.7, λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.  \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "    \n",
    "def show_grey_img(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def show_selected_region(img, top_left, top_right, bottom_left, bottom_right):\n",
    "    x = [top_left[0], top_right[0], bottom_right[0], bottom_left[0], top_left[0]]\n",
    "    y = [top_left[1], top_right[1], bottom_right[1], bottom_left[1], top_left[1]]\n",
    "    line_chart = plt.plot(x, y, 'r')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    import math\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    \n",
    "    negative_slopes = []\n",
    "    positive_slopes = []\n",
    "    \n",
    "    negetive_intercepts = []\n",
    "    positive_intercepts = []\n",
    "    \n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    \n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "    \n",
    "    y_max = img.shape[0]\n",
    "    y_min = img.shape[0]\n",
    "    \n",
    "    # The idea of this algorithm is \n",
    "    # 1. separate line segments into left and right lines\n",
    "    # 2. Then for each line\n",
    "    #    2.1 calculate average slope and intercept\n",
    "    # 3. considering all line segments calculate y_min value\n",
    "    # 4. Set height of the image into the y_max value\n",
    "    # 5. For both left and right lines:\n",
    "    #   5.1 calculate x_min and x_max values using intercept, slope, y_min and y_max\n",
    "    #   5.2 Draw a line using (x_min, y_min) and (x_max, y_max)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            current_slope = (y2-y1)/(x2-x1)\n",
    "            \n",
    "            if current_slope < 0.0 and current_slope > -math.inf:\n",
    "                negative_slopes.append(current_slope) # left line\n",
    "                left_line_x.append(x1)\n",
    "                left_line_x.append(x2)\n",
    "                left_line_y.append(y1)\n",
    "                left_line_y.append(y2)\n",
    "                negetive_intercepts.append(y1 -current_slope*x1)\n",
    "            \n",
    "            if current_slope > 0.0 and current_slope < math.inf:\n",
    "                positive_slopes.append(current_slope) # right line\n",
    "                right_line_x.append(x1)\n",
    "                right_line_x.append(x2)\n",
    "                right_line_y.append(y1)\n",
    "                right_line_y.append(y2)\n",
    "                positive_intercepts.append(y1 - current_slope*x1)\n",
    "                \n",
    "            y_min = min(y_min, y1, y2)\n",
    "                    \n",
    "    y_min += 15 # add small threshold\n",
    "    \n",
    "    if len(positive_slopes) > 0 and len(right_line_x) > 0 and len(right_line_y) > 0:\n",
    "        ave_positive_slope = sum(positive_slopes) / len(positive_slopes)\n",
    "        ave_right_line_x = sum(right_line_x) / len(right_line_x)\n",
    "        ave_right_line_y = sum(right_line_y ) / len(right_line_y)\n",
    "        intercept = sum(positive_intercepts) / len(positive_intercepts)    \n",
    "        x_min=int((y_min-intercept)/ave_positive_slope) \n",
    "        x_max = int((y_max - intercept)/ ave_positive_slope)\n",
    "        cv2.line(img, (x_min, y_min), (x_max, y_max), [122, 1, 255], 12)\n",
    "\n",
    "    if len(negative_slopes) > 0 and len(left_line_x) > 0 and len(left_line_y) > 0:\n",
    "        ave_negative_slope = sum(negative_slopes) / len(negative_slopes)\n",
    "        ave_left_line_x = sum(left_line_x) / len(left_line_x)\n",
    "        ave_left_line_y = sum(left_line_y ) / len(left_line_y)\n",
    "        intercept = sum(negetive_intercepts) / len(negetive_intercepts)\n",
    "        x_min = int((y_min-intercept)/ave_negative_slope) \n",
    "        x_max = int((y_max - intercept)/ ave_negative_slope)\n",
    "        cv2.line(img, (x_min, y_min), (x_max, y_max), [122, 1, 255], 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lane lines in the image\n",
    "def find_lane_lines(image):\n",
    "#     print(\"Grayscale image\")\n",
    "    grayscale_image = grayscale(image)\n",
    "#     show_grey_img(grayscale_image)\n",
    "    \n",
    "#     print(\"Smoothed image\")\n",
    "    smooth_image = gaussian_blur(grayscale_image, KERNEL_SIZE)\n",
    "#     show_grey_img(smooth_image)\n",
    "    \n",
    "#     print(\"Image with canny egdes\")\n",
    "    edges_img = canny(smooth_image, LOW_THRESHOLD, HIGH_THRESHOLD)\n",
    "#     show_grey_img(edges_img)\n",
    "    \n",
    "#     print (\"Selected region\")\n",
    "    top_left, top_right, bottom_left, bottom_right = get_selected_region(edges_img)\n",
    "#     show_selected_region(image, top_left, top_right, bottom_left, bottom_right)\n",
    "    \n",
    "#     print(\"Masked image\")\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32) \n",
    "    masked_img = region_of_interest(edges_img, vertices)\n",
    "#     show_grey_img(masked_img)\n",
    "    \n",
    "#     print(\"Hough image\")\n",
    "    hough_image = hough_lines(masked_img, RHO, THETA, MIN_VOTES, MIN_LINE_LEN, MAX_LINE_GAP)\n",
    "#     show_grey_img(hough_image)\n",
    "    \n",
    "    return weighted_img(hough_image, image)\n",
    "\n",
    "import os\n",
    "for test_image in os.listdir(\"test_images/\"):\n",
    "    img = mpimg.imread('test_images/' + test_image)\n",
    "    lane_lines_img = find_lane_lines(img)\n",
    "#     print(\"Final image\")\n",
    "#     plt.imshow(lane_lines_img)\n",
    "#     plt.show()\n",
    "#     print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output = 'solidWhiteRight_output.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(find_lane_lines) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_output = 'solidYellowLeft_output.mp4'\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(find_lane_lines)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_output = 'challenge_output.mp4'\n",
    "clip2 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(find_lane_lines)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"950\" height=\"400\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
